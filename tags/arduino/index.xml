<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Arduino on Jesús Vargas Portfolio</title><link>https://jmvargascruz.github.io/tags/arduino/</link><description>Recent content in Arduino on Jesús Vargas Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 01 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://jmvargascruz.github.io/tags/arduino/index.xml" rel="self" type="application/rss+xml"/><item><title>Autonomous Mobile Vehicle</title><link>https://jmvargascruz.github.io/projects/amr/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://jmvargascruz.github.io/projects/amr/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>We developed an Autonomous Mobile Vehicle using a combination of Jetson Xavier for high-level processing, RPLIDAR A3 for mapping and localization, and an Arduino Mega for low-level actuation. Our team designed and implemented the electrical system, control interfaces, CAD mounts, and ROS integration. The AGV successfully navigated autonomously within the mapped area of CIMA using ROS, Hector SLAM, and TEB Local Planner.&lt;/p>
&lt;h2 id="project-highlights">Project Highlights:&lt;/h2>
&lt;ul>
&lt;li>Designed and fabricated a reinforced electrical wiring system&lt;/li>
&lt;li>Integrated voltage converters (48V to 12V, 12V to 5V, 12V to 19V) for safe and efficient power management.&lt;/li>
&lt;li>Replaced the steering motor with a 24V scooter motor and sprocket system, integrating a potentiometer for angular feedback.&lt;/li>
&lt;li>Mounted the RPLIDAR on a custom laser-cut platform aligned with the vehicle’s center.&lt;/li>
&lt;li>Installed Jetson Xavier with secure custom mount and configured ROS-based autonomous navigation.&lt;/li>
&lt;li>Generated a live map of the CIMA building and planned paths using Hector SLAM and TEB Planner.&lt;/li>
&lt;li>Programmed mode switching between autonomous and manual via RC control&lt;/li>
&lt;li>Developed and deployed Python ROS nodes to communicate velocity commands using ROS Serial&lt;/li>
&lt;/ul>
&lt;h2 id="technologies-and-tools-used">Technologies and Tools Used&lt;/h2>
&lt;ul>
&lt;li>Hardware: Jetson Xavier, Arduino Mega, RPLIDAR A3, DC motors, step-down converters, relays.&lt;/li>
&lt;li>Software: ROS, RViz, Hector SLAM, TEB Planner, Python, GIMP, SolidWorks&lt;/li>
&lt;/ul>
&lt;h2 id="gallery">Gallery&lt;/h2>
&lt;div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 10px;">
&lt;img src="images/agv.png" alt="AMR">
&lt;img src="images/map.png" alt="map">
&lt;img src="images/grid.png" alt="grid
">
&lt;/div></description></item><item><title>Gripper Design for Tomato Harvesting</title><link>https://jmvargascruz.github.io/projects/gripper-design/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://jmvargascruz.github.io/projects/gripper-design/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This project was part of an international university challenge focused on autonomous tomato harvesting, conducted in collaboration with Mondragon Unibertsitatea and Tecnológico de Monterrey. The main contribution involved designing and building a functional gripper prototype for the robotic system.&lt;/p>
&lt;p>The end-effector was developed using 3D-printed components and included an integrated stepper motor, limit switch, and potentiometer. The control system was implemented on an Arduino UNO, which managed the opening and closing of the gripper based on sensor inputs.&lt;/p></description></item><item><title>Interactive Laser Harp</title><link>https://jmvargascruz.github.io/projects/music-laser-harp/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://jmvargascruz.github.io/projects/music-laser-harp/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This project consists of a laser harp, an interactive musical instrument that generates sound when a user interrupts visible laser beams with their hand. Each laser beam corresponds to a musical note. When the beam is blocked, the system detects the change and activates a tone through a built-in speaker.&lt;/p>
&lt;p>The device is built on a curved wooden and plastic frame with multiple red laser diodes aligned with photodetectors (photodiodes). An Arduino microcontroller continuously reads each sensor and triggers a specific tone based on which beam was interrupted. A rotary selector allows the user to switch between rhythm or tone modes.&lt;/p></description></item><item><title>Self-Targeting Laser Turret</title><link>https://jmvargascruz.github.io/projects/laser-turret/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://jmvargascruz.github.io/projects/laser-turret/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This project involved designing and implementing a two-axis laser turret capable of tracking a moving red circular target in real-time. The system integrates a webcam, MATLAB for image processing, and an Arduino for PID-based actuation. The goal was to keep a laser pointer aimed at the target within a 1 m × 1 m workspace for at least 20 continuous seconds.&lt;/p>
&lt;h2 id="system-description">System Description&lt;/h2>
&lt;p>The vision subsystem detects the position of a red object using color segmentation in MATLAB. This position is sent to the Arduino through serial communication. The Arduino processes the coordinates and drives two DC motors via a manually tuned PID controller to align the turret accordingly.&lt;/p></description></item><item><title>Sensor Module | USB HID Interface</title><link>https://jmvargascruz.github.io/projects/sensor-module/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://jmvargascruz.github.io/projects/sensor-module/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This module connects sensors from a driving simulator using RJ45 Keystone jacks and custom wiring. It includes signals such as blinkers, gear selector, handbrake, seatbelt, and ignition. Each sensor is mapped to a virtual joystick button through a USB HID interface.&lt;/p>
&lt;p>The firmware handles input logic and emulates a USB joystick using the Joystick.h library. The module is housed in a 3D-printed case and has a custom PCB prepared for future versions.&lt;/p></description></item></channel></rss>